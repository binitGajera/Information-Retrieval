# Part 1 of the Project

This phase of the project focuses on tokenization of the documents. Here, we will convert our all *html* files to text format with **ISO** encoding.

## Objective

We can consider this part of the project as pre-processing on the dataset, where before we find all the word tokens and word types we can modify the words and punctuations and other words as per our requirements. If we need to remove some words such as stopwords then that too can be done using this code but we will be performing that in the later part of the project using a specific stopwords list that is common in some of the NLP tasks.

The code from this phase will result:

* A directory of all tokenized documents
* A file of all tokens and their frequencies sorted by token
* A file of all tokens and their frequencies sorted by frequency.
